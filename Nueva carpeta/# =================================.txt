# ========================================
# CNN CHEST X-RAY - SCRIPT COMPLETO
# TODO EN UNA SOLA CELDA PARA EVITAR ERRORES
# ========================================

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from pathlib import Path
from sklearn.model_selection import train_test_split

print("üöÄ CNN CHEST X-RAY - SCRIPT COMPLETO")
print("=" * 50)

# Configuraci√≥n
IMAGE_SIZE = (150, 150)
BATCH_SIZE = 32
EPOCHS = 25

print(f"‚öôÔ∏è Configuraci√≥n:")
print(f"   ‚Ä¢ Tama√±o imagen: {IMAGE_SIZE}")
print(f"   ‚Ä¢ Batch size: {BATCH_SIZE}")
print(f"   ‚Ä¢ √âpocas: {EPOCHS}")

# ========================================
# PASO 1: CARGAR Y VERIFICAR DATOS
# ========================================

print(f"\nüìä PASO 1: CARGANDO DATOS")
print("-" * 40)

# Cargar CSV
try:
    df = pd.read_csv("nuestras_imagenes_metadata.csv")
 print(f"‚úÖ CSV cargado: {len(df):,} im√°genes")
    print(f"üìã Columnas disponibles: {list(df.columns)}")
except FileNotFoundError:
    print("‚ùå No se encontr√≥ 'nuestras_imagenes_metadata.csv'")
    print("üí° Ejecuta primero el notebook de an√°lisis CSV")
    raise SystemExit("Archivo CSV no encontrado")

# Verificar carpeta de im√°genes
images_path = "extracted_images"
if not os.path.exists(images_path):
    print(f"‚ùå Carpeta no existe: {images_path}")
    raise SystemExit("Carpeta de im√°genes no encontrada")

print(f"‚úÖ Carpeta encontrada: {images_path}")

# ========================================
# PASO 2: PREPARAR CLASES Y RUTAS
# ========================================

print(f"\nüè• PASO 2: PREPARANDO CLASES Y RUTAS")
print("-" * 40)

# Funci√≥n de clasificaci√≥n
def classify_disease(finding_labels):
    if pd.isna(finding_labels) or finding_labels == 'No Finding':
        return 'Normal'
    elif any(disease in str(finding_labels) for disease in ['Pneumonia', 'Infiltration', 'Consolidation']):
        return 'Infeccion'
    elif any(disease in str(finding_labels) for disease in ['Cardiomegaly', 'Edema', 'Effusion']):
        return 'Cardiaco'
    else:
        return 'Normal'

# Crear categor√≠as
df['Disease_Category'] = df['Finding Labels'].apply(classify_disease)

# Crear rutas completas
df['full_path'] = df['Image Index'].apply(lambda x: os.path.join(images_path, x))

print(f"üìä Distribuci√≥n de clases:")
for category, count in df['Disease_Category'].value_counts().items():
    percentage = count / len(df) * 100
    print(f"   ‚Ä¢ {category}: {count:,} ({percentage:.1f}%)")
   
# Verificar que las im√°genes existen
print(f"\nüîç Verificando rutas:")
sample_paths = df['full_path'].head(3).tolist()
for path in sample_paths:
    exists = os.path.exists(path)
    print(f"   ‚Ä¢ {os.path.basename(path)}: {'‚úÖ' if exists else '‚ùå'}")

# Filtrar solo im√°genes existentes
existing_mask = df['full_path'].apply(os.path.exists)
df_clean = df[existing_mask].copy()

print(f"‚úÖ Im√°genes verificadas: {len(df_clean):,} de {len(df):,}")

if len(df_clean) < 100:
    print(f"‚ùå Muy pocas im√°genes para entrenar (m√≠nimo 100)")
    raise SystemExit("Insuficientes im√°genes para entrenamiento")

# ========================================
# PASO 3: DIVIDIR DATOS
# ========================================

print(f"\nüîÑ PASO 3: DIVIDIENDO DATOS")
print("-" * 40)

# Dividir en entrenamiento y validaci√≥n
train_df, val_df = train_test_split(
    df_clean, 
    test_size=0.2, 
    random_state=42,
    stratify=df_clean['Disease_Category']
)

print(f"üìä Divisi√≥n:")
print(f"   ‚Ä¢ Entrenamiento: {len(train_df):,}")
print(f"   ‚Ä¢ Validaci√≥n: {len(val_df):,}")
# Verificar que ambos DataFrames tienen la columna full_path
print(f"üìã Columnas en train_df: {list(train_df.columns)}")
print(f"üìã Columnas en val_df: {list(val_df.columns)}")

# ========================================
# PASO 4: CREAR GENERADORES
# ========================================

print(f"\nüîÑ PASO 4: CREANDO GENERADORES")
print("-" * 40)

# Generadores de datos
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Crear generadores
print("üîÑ Creando generador de entrenamiento...")
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col='full_path',
    y_col='Disease_Category',
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True
)

print("üîÑ Creando generador de validaci√≥n...")
val_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    x_col='full_path',
    y_col='Disease_Category',
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

print(f"‚úÖ Generadores creados exitosamente:")
print(f"   ‚Ä¢ Training batches: {len(train_generator)}")
print(f"   ‚Ä¢ Validation batches: {len(val_generator)}")
print(f"   ‚Ä¢ Clases encontradas: {train_generator.class_indices}")
# ========================================
# PASO 5: CREAR MODELO
# ========================================

print(f"\nüß† PASO 5: CREANDO MODELO CNN")
print("-" * 40)

model = Sequential([
    # Primera capa convolucional
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),
    MaxPooling2D((2, 2)),
    
    # Segunda capa convolucional
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    
    # Tercera capa convolucional
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    
    # Capas densas
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # 3 clases: Normal, Infeccion, Cardiaco
])# Compilar modelo
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print(f"‚úÖ Modelo CNN creado:")
model.summary()

# ========================================
# PASO 6: ENTRENAR MODELO
# ========================================

print(f"\nüöÄ PASO 6: ENTRENANDO MODELO")
print("=" * 50)

# Callbacks √∫tiles
callbacks = [
    keras.callbacks.ModelCheckpoint(
        'best_chest_xray_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-7,
        verbose=1
    ),
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True,
        verbose=1
    )
]
# ¬°ENTRENAR!
print(f"üî• Comenzando entrenamiento por {EPOCHS} √©pocas...")
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=EPOCHS,
    validation_data=val_generator,
    validation_steps=len(val_generator),
    callbacks=callbacks,
    verbose=1
)

print(f"üéâ ¬°ENTRENAMIENTO COMPLETADO!")

# Guardar modelo final
model.save('chest_xray_final_model.h5')
print(f"üíæ Modelo guardado: chest_xray_final_model.h5")

# ========================================
# PASO 7: VISUALIZAR RESULTADOS
# ========================================

print(f"\nüìà PASO 7: VISUALIZANDO RESULTADOS")
print("-" * 40)

# Crear gr√°ficos de entrenamiento
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Gr√°fico de p√©rdida
ax1.plot(history.history['loss'], 'b-', label='Entrenamiento', linewidth=2)
ax1.plot(history.history['val_loss'], 'r-', label='Validaci√≥n', linewidth=2)
ax1.set_title('P√©rdida durante el Entrenamiento', fontsize=14)
ax1.set_xlabel('√âpoca')
ax1.set_ylabel('P√©rdida')
ax1.legend()
ax1.grid(True, alpha=0.3)
# Gr√°fico de precisi√≥n
ax2.plot(history.history['accuracy'], 'b-', label='Entrenamiento', linewidth=2)
ax2.plot(history.history['val_accuracy'], 'r-', label='Validaci√≥n', linewidth=2)
ax2.set_title('Precisi√≥n durante el Entrenamiento', fontsize=14)
ax2.set_xlabel('√âpoca')
ax2.set_ylabel('Precisi√≥n')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chest_xray_training_results.png', dpi=300, bbox_inches='tight')
plt.show()

# Mostrar estad√≠sticas finales
best_val_acc = max(history.history['val_accuracy'])
best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1
final_train_acc = history.history['accuracy'][-1]
final_val_acc = history.history['val_accuracy'][-1]

print(f"\nüèÜ RESULTADOS FINALES:")
print(f"   ‚Ä¢ Mejor √©poca: {best_epoch}")
print(f"   ‚Ä¢ Mejor precisi√≥n validaci√≥n: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)")
print(f"   ‚Ä¢ Precisi√≥n final entrenamiento: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)")
print(f"   ‚Ä¢ Precisi√≥n final validaci√≥n: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)")
# ========================================
# PASO 8: FUNCI√ìN DE PREDICCI√ìN
# ========================================

def predict_chest_xray(image_path):
    """Predecir enfermedad en una imagen de rayos X"""
    
    from keras.preprocessing import image
    
    # Cargar y procesar imagen
    test_image = image.load_img(image_path, target_size=IMAGE_SIZE)
    test_image = image.img_to_array(test_image)
    test_image = np.expand_dims(test_image, axis=0)
    test_image = test_image / 255.0  # Normalizar
    
    # Realizar predicci√≥n
    prediction = model.predict(test_image, verbose=0)
  # Mapeo de clases (basado en train_generator.class_indices)
    class_names = list(train_generator.class_indices.keys())
    predicted_class_idx = np.argmax(prediction[0])
    predicted_class = class_names[predicted_class_idx]
    confidence = prediction[0][predicted_class_idx]
    
    print(f"üîç PREDICCI√ìN PARA: {os.path.basename(image_path)}")
    print(f"   üéØ Clase predicha: {predicted_class}")
    print(f"   üìä Confianza: {confidence:.2%}")
    
    print(f"   üìã Probabilidades detalladas:")
    for i, (class_name, prob) in enumerate(zip(class_names, prediction[0])):
        emoji = "üéØ" if i == predicted_class_idx else "  "
        print(f"   {emoji} {class_name}: {prob:.2%}")
    
    return predicted_class, confidence

print(f"\n‚úÖ ENTRENAMIENTO COMPLETADO EXITOSAMENTE!")
print("=" * 50)
print(f"üéØ ARCHIVOS GENERADOS:")
print(f"   ‚Ä¢ best_chest_xray_model.h5 - Mejor modelo")
print(f"   ‚Ä¢ chest_xray_final_model.h5 - Modelo final")
print(f"   ‚Ä¢ chest_xray_training_results.png - Gr√°ficos")

print(f"\nüõ†Ô∏è FUNCI√ìN DISPONIBLE:")
print(f"   ‚Ä¢ predict_chest_xray('ruta/imagen.png')")

print(f"\nüöÄ ¬°Tu clasificador de radiograf√≠as est√° listo!")

------------------------------------------------
# ========================================
# CNN CHEST X-RAY - C√ìDIGO LIMPIO Y CORREGIDO
# ========================================

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from pathlib import Path
from sklearn.model_selection import train_test_split

print("üöÄ CNN CHEST X-RAY - VERSI√ìN CORREGIDA")
print("=" * 40)

# ========================================
# 1. CONFIGURACI√ìN
# ========================================

IMAGE_SIZE = (150, 150)
BATCH_SIZE = 32
EPOCHS = 25

print(f"‚öôÔ∏è Configuraci√≥n:")
print(f"   ‚Ä¢ Tama√±o imagen: {IMAGE_SIZE}")
print(f"   ‚Ä¢ Batch size: {BATCH_SIZE}")
print(f"   ‚Ä¢ √âpocas: {EPOCHS}")

# ========================================
# 2. CARGAR DATOS
# ========================================

print(f"\nüìä CARGANDO DATOS")
print("-" * 30)

# Cargar CSV
try:
    df = pd.read_csv("nuestras_imagenes_metadata.csv")
    print(f"‚úÖ CSV cargado: {len(df):,} im√°genes")
except FileNotFoundError:
    print("‚ùå No se encontr√≥ el CSV")
    df = None

# Encontrar im√°genes (basado en tu diagn√≥stico)
images_path = "extracted_images"
if df is not None:
    if os.path.exists(images_path):
        print(f"‚úÖ Carpeta encontrada: {images_path}")
    else:
        print(f"‚ùå Carpeta no existe: {images_path}")
        images_path = None

# ========================================
# 3. PREPARAR CLASES
# ========================================

if df is not None:
    print(f"\nüè• PREPARANDO CLASES")
    print("-" * 30)
    
    def classify_disease(finding_labels):
        if pd.isna(finding_labels) or finding_labels == 'No Finding':
            return 'Normal'
        elif any(disease in str(finding_labels) for disease in ['Pneumonia', 'Infiltration', 'Consolidation']):
            return 'Infeccion'
        elif any(disease in str(finding_labels) for disease in ['Cardiomegaly', 'Edema', 'Effusion']):
            return 'Cardiaco'
        else:
            return 'Normal'
    
    df['Disease_Category'] = df['Finding Labels'].apply(classify_disease)
    
    print(f"üìä Distribuci√≥n de clases:")
    for category, count in df['Disease_Category'].value_counts().items():
        percentage = count / len(df) * 100
        print(f"   ‚Ä¢ {category}: {count:,} ({percentage:.1f}%)")

# ========================================
# 4. CREAR DATAFRAME CON RUTAS
# ========================================

if df is not None and images_path is not None:
    print(f"\nüîÑ PREPARANDO RUTAS")
    print("-" * 30)
    
    # Crear rutas completas
    df['full_path'] = df['Image Index'].apply(lambda x: os.path.join(images_path, x))
    
    # Verificar algunas rutas de ejemplo
    print(f"üîç Verificando rutas de ejemplo:")
    sample_paths = df['full_path'].head(3).tolist()
    for path in sample_paths:
        exists = os.path.exists(path)
        print(f"   ‚Ä¢ {os.path.basename(path)}: {'‚úÖ' if exists else '‚ùå'}")
    
    # Filtrar solo im√°genes que existen
    existing_mask = df['full_path'].apply(os.path.exists)
    df_clean = df[existing_mask].copy()
    
    print(f"‚úÖ Im√°genes verificadas: {len(df_clean):,} de {len(df):,}")
    
    if len(df_clean) > 100:  # M√≠nimo para entrenar
        print(f"‚úÖ Suficientes im√°genes para entrenar!")
    else:
        print(f"‚ùå Muy pocas im√°genes encontradas")
        df_clean = None

# ========================================
# 5. DIVIDIR DATOS
# ========================================

if 'df_clean' in locals() and df_clean is not None and len(df_clean) > 100:
    print(f"\nüîÑ DIVIDIENDO DATOS")
    print("-" * 30)
    
    # Dividir en entrenamiento y validaci√≥n
    train_df, val_df = train_test_split(
        df_clean, 
        test_size=0.2, 
        random_state=42,
        stratify=df_clean['Disease_Category']
    )
    
    print(f"üìä Divisi√≥n:")
    print(f"   ‚Ä¢ Entrenamiento: {len(train_df):,}")
    print(f"   ‚Ä¢ Validaci√≥n: {len(val_df):,}")

# ========================================
# 6. CONFIGURAR GENERADORES
# ========================================

if 'train_df' in locals():
    print(f"\nüîÑ CONFIGURANDO GENERADORES")
    print("-" * 30)
    
    # Generador de entrenamiento
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    # Generador de validaci√≥n
    val_datagen = ImageDataGenerator(rescale=1./255)
    
    # Crear generadores
    train_generator = train_datagen.flow_from_dataframe(
        dataframe=train_df,
        x_col='full_path',
        y_col='Disease_Category',
        target_size=IMAGE_SIZE,
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        shuffle=True
    )
    
    val_generator = val_datagen.flow_from_dataframe(
        dataframe=val_df,
        x_col='full_path',
        y_col='Disease_Category',
        target_size=IMAGE_SIZE,
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        shuffle=False
    )
    
    print(f"‚úÖ Generadores creados:")
    print(f"   ‚Ä¢ Training batches: {len(train_generator)}")
    print(f"   ‚Ä¢ Validation batches: {len(val_generator)}")
    print(f"   ‚Ä¢ Clases: {train_generator.class_indices}")

# ========================================
# 7. CREAR MODELO
# ========================================

if 'train_generator' in locals():
    print(f"\nüß† CREANDO MODELO")
    print("-" * 30)
    
    model = Sequential()
    
    # Capas convolucionales
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)))
    model.add(MaxPooling2D((2, 2)))
    
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    
    # Capas densas
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(3, activation='softmax'))  # 3 clases
    
    # Compilar
    model.compile(
        optimizer='adam',   loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print(f"‚úÖ Modelo creado")
    model.summary()

# ========================================
# 8. ENTRENAMIENTO
# ========================================

if 'model' in locals() and 'train_generator' in locals():
    print(f"\nüöÄ INICIANDO ENTRENAMIENTO")
    print("-" * 40)
    
    # Entrenar modelo
    history = model.fit(
        train_generator,
        steps_per_epoch=len(train_generator),
        epochs=EPOCHS,
        validation_data=val_generator,
        validation_steps=len(val_generator),
        verbose=1
    )
    
    print(f"üéâ ¬°Entrenamiento completado!")
    
    # Guardar modelo
    model.save('chest_xray_model.h5')
    print(f"üíæ Modelo guardado: chest_xray_model.h5")

# ========================================
# 9. VISUALIZAR RESULTADOS
# ========================================

if 'history' in locals():
    print(f"\nüìà CREANDO GR√ÅFICOS")
    print("-" * 30)
    
    # Crear gr√°ficos
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # P√©rdida
    ax1.plot(history.history['loss'], label='Entrenamiento')
    ax1.plot(history.history['val_loss'], label='Validaci√≥n')
    ax1.set_title('P√©rdida durante el entrenamiento')
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('P√©rdida')
    ax1.legend()
    ax1.grid(True)
    
    # Precisi√≥n
    ax2.plot(history.history['accuracy'], label='Entrenamiento')
    ax2.plot(history.history['val_accuracy'], label='Validaci√≥n')
    ax2.set_title('Precisi√≥n durante el entrenamiento')
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('Precisi√≥n')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('training_results.png', dpi=300)
    plt.show()
    
    # Mostrar mejores resultados
    best_val_acc = max(history.history['val_accuracy'])
    best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1
    
    print(f"üèÜ MEJORES RESULTADOS:")
    print(f"   ‚Ä¢ Mejor √©poca: {best_epoch}")
    print(f"   ‚Ä¢ Mejor Val Accuracy: {best_val_acc:.4f}")
    print(f"   ‚Ä¢ Train Accuracy final: {history.history['accuracy'][-1]:.4f}")

# ========================================
# 10. FUNCI√ìN DE PREDICCI√ìN
# ========================================

def predict_chest_xray(image_path):
    """Predecir enfermedad en una imagen"""
    
    if 'model' not in globals():
        print("‚ùå Modelo no entrenado a√∫n")
        return
    
    from keras.preprocessing import image
    
    # Cargar imagen
    test_image = image.load_img(image_path, target_size=IMAGE_SIZE)
    test_image = image.img_to_array(test_image)
    test_image = np.expand_dims(test_image, axis=0)
    test_image = test_image / 255.0
    
    # Predecir
    result = model.predict(test_image)
    
    # Clases
    class_names = ['Cardiaco', 'Infeccion', 'Normal']
    predicted_class = np.argmax(result[0])
    confidence = result[0][predicted_class]
    
    print(f"üîç Predicci√≥n para: {os.path.basename(image_path)}")
    print(f"   ‚Ä¢ Clase: {class_names[predicted_class]}")
    print(f"   ‚Ä¢ Confianza: {confidence:.2%}")
        # Mostrar todas las probabilidades
    print(f"   ‚Ä¢ Probabilidades:")
    for i, (class_name, prob) in enumerate(zip(class_names, result[0])):
        print(f"     - {class_name}: {prob:.2%}")

print(f"\n‚úÖ C√ìDIGO COMPLETADO")
print("=" * 40)
print("üõ†Ô∏è Funci√≥n disponible:")
print("   ‚Ä¢ predict_chest_xray('ruta/imagen.png')")

if 'history' not in locals():
    print("\nüí° Para completar el entrenamiento, aseg√∫rate de tener:")
    print("   ‚Ä¢ El archivo 'nuestras_imagenes_metadata.csv'")
    print("   ‚Ä¢ La carpeta 'extracted_images' con las im√°genes PNG")

# ========================================
# COMPLETANDO TU PIPELINE CNN
# Solo agregamos lo que te falta
# ========================================

# Tus imports (ya los tienes)
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd
import matplotlib.pyplot as plt

print("üöÄ COMPLETANDO TU CNN PIPELINE")
print("=" * 40)

# ========================================
# PASO 1-4: YA LOS TIENES ‚úÖ
# Tu modelo CNN ya est√° creado y compilado
# ========================================

# Configuraci√≥n (la que ya tienes)
IMAGE_SIZE = 64  # o el que est√©s usando
BATCH_SIZE = 32
EPOCHS = 10

print("‚úÖ Pasos 1-4 ya completados (modelo creado)")

# ========================================
# LO QUE TE FALTA: CARGAR Y PREPARAR DATOS REALES
# ========================================

print("\nüìä CARGANDO TUS DATOS REALES")
print("-" * 40)

# Cargar el CSV que ya tienes
try:
    df = pd.read_csv("nuestras_imagenes_metadata.csv")
    print(f"‚úÖ CSV cargado: {len(df):,} im√°genes")
    
    # Clasificar en 3 categor√≠as simples
    def classify_simple(finding_labels):
        if pd.isna(finding_labels) or finding_labels == 'No Finding':
            return 'Normal'
        elif 'Pneumonia' in str(finding_labels) or 'Infiltration' in str(finding_labels):
            return 'Infeccion'
        elif 'Cardiomegaly' in str(finding_labels) or 'Edema' in str(finding_labels):
            return 'Cardiaco'
        else:
            return 'Normal'
    
    df['Disease_Category'] = df['Finding Labels'].apply(classify_simple)
    df['full_path'] = df['Image Index'].apply(lambda x: f"extracted_images/{x}")
    
    # Solo im√°genes que existen
    import os
    existing_mask = df['full_path'].apply(os.path.exists)
    df_clean = df[existing_mask].copy()
    
    print(f"‚úÖ Im√°genes verificadas: {len(df_clean):,}")
    print(f"üìä Clases: {df_clean['Disease_Category'].value_counts().to_dict()}")
    
except FileNotFoundError:
    print("‚ùå CSV no encontrado - usa datos de ejemplo")
    # C√≥digo para crear datos de ejemplo si no tienes el CSV

# ========================================
# LO QUE TE FALTA: CONFIGURAR TUS GENERADORES
# ========================================

print(f"\nüîÑ CONFIGURANDO GENERADORES CON TUS DATOS")
print("-" * 40)

if 'df_clean' in locals() and len(df_clean) > 100:
    
    # Dividir datos
    from sklearn.model_selection import train_test_split
    train_df, val_df = train_test_split(df_clean, test_size=0.2, random_state=42)
    
    # Tus generadores (ya los tienes, solo los aplicamos a datos reales)
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    val_datagen = ImageDataGenerator(rescale=1./255)
    
    # Crear generadores con tus datos reales
    train_generator = train_datagen.flow_from_dataframe(
        dataframe=train_df,
        x_col='full_path',
        y_col='Disease_Category', 
        target_size=(IMAGE_SIZE, IMAGE_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        shuffle=True
    )
    
    val_generator = val_datagen.flow_from_dataframe(
        dataframe=val_df,
        x_col='full_path',
        y_col='Disease_Category',
        target_size=(IMAGE_SIZE, IMAGE_SIZE), 
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        shuffle=False
    )
    
    print(f"‚úÖ Generadores listos:")
    print(f"   ‚Ä¢ Training: {len(train_generator)} batches")
    print(f"   ‚Ä¢ Validation: {len(val_generator)} batches")
    print(f"   ‚Ä¢ Clases encontradas: {train_generator.class_indices}")
    
    generators_ready = True
else:
    print("‚ùå No hay suficientes datos para entrenar")
    generators_ready = False

# ========================================
# LO QUE TE FALTA: ENTRENAR EL MODELO
# ========================================

if generators_ready:
    print(f"\nüöÄ ENTRENANDO TU MODELO CNN")
    print("-" * 40)
    
    # Aqu√≠ usas tu modelo que ya creaste
    # classifier.fit(...) - usando el nombre que tienes
    
    print("üî• Comenzando entrenamiento...")
    
    # AQU√ç VA TU L√çNEA DE ENTRENAMIENTO
    history = classifier.fit(  # ‚Üê Usa el nombre de tu modelo
        train_generator,
        steps_per_epoch=len(train_generator),
        epochs=EPOCHS,
        validation_data=val_generator,
        validation_steps=len(val_generator),
        verbose=1
    )
    
    print("üéâ ¬°Entrenamiento completado!")
    
    # Guardar modelo
    classifier.save('mi_modelo_radiografias.h5')
    print("üíæ Modelo guardado como: mi_modelo_radiografias.h5")

# ========================================
# LO QUE TE FALTA: VISUALIZAR RESULTADOS
# ========================================

if 'history' in locals():
    print(f"\nüìà VISUALIZANDO RESULTADOS")
    print("-" * 40)
    
    # Gr√°ficos simples como en tu imagen
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Accuracy
    ax1.plot(history.history['accuracy'], label='Training')
    ax1.plot(history.history['val_accuracy'], label='Validation') 
    ax1.set_title('Accuracy')
    ax1.set_xlabel('Epochs')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True)
    
    # Loss
    ax2.plot(history.history['loss'], label='Training')
    ax2.plot(history.history['val_loss'], label='Validation')
    ax2.set_title('Loss') 
    ax2.set_xlabel('Epochs')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('resultados_entrenamiento.png')
    plt.show()
    
    # Mostrar mejores resultados
    best_acc = max(history.history['val_accuracy'])
    final_acc = history.history['val_accuracy'][-1]
    
    print(f"üèÜ RESULTADOS:")
    print(f"   ‚Ä¢ Mejor accuracy: {best_acc:.3f} ({best_acc*100:.1f}%)")
    print(f"   ‚Ä¢ Accuracy final: {final_acc:.3f} ({final_acc*100:.1f}%)")

# ========================================
# LO QUE TE FALTA: FUNCI√ìN DE PREDICCI√ìN
# ========================================

def predecir_radiografia(ruta_imagen):
    """Predecir enfermedad en una radiograf√≠a"""
    
    from keras.preprocessing import image
    import numpy as np
    
    # Cargar imagen
    img = image.load_img(ruta_imagen, target_size=(IMAGE_SIZE, IMAGE_SIZE))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0  # Normalizar
    
    # Predecir
    prediction = classifier.predict(img_array)
    
    # Clases (ajusta seg√∫n tus datos)
    clases = ['Cardiaco', 'Infeccion', 'Normal']  # Orden alfab√©tico por defecto
    
    # Resultado
    clase_predicha = clases[np.argmax(prediction)]
    confianza = np.max(prediction)
    
    print(f"üîç Predicci√≥n: {clase_predicha}")
    print(f"üìä Confianza: {confianza:.2%}")
    
    return clase_predicha, confianza

print(f"\n‚úÖ PIPELINE COMPLETADO")
print("=" * 40)
print("üõ†Ô∏è Funciones disponibles:")
print("   ‚Ä¢ predecir_radiografia('ruta/imagen.png')")
print("\nüéØ Archivos generados:")  
print("   ‚Ä¢ mi_modelo_radiografias.h5")
print("   ‚Ä¢ resultados_entrenamiento.png")

# ========================================
# C√ìDIGO M√çNIMO PARA COPIAR (si prefieres)
# ========================================

codigo_minimo = '''
# C√ìDIGO M√çNIMO PARA AGREGAR A LO QUE YA TIENES:

# 1. Cargar datos
df = pd.read_csv("nuestras_imagenes_metadata.csv")
df['Disease_Category'] = df['Finding Labels'].apply(lambda x: 'Normal' if pd.isna(x) else 'Infeccion')
df['full_path'] = df['Image Index'].apply(lambda x: f"extracted_images/{x}")

# 2. Crear generadores  
train_generator = train_datagen.flow_from_dataframe(df, 'full_path', 'Disease_Category', (64,64), 32, 'categorical')

# 3. Entrenar
history = classifier.fit(train_generator, epochs=10)

# 4. Guardar
classifier.save('modelo.h5')
'''

print(f"\nüìù C√ìDIGO M√çNIMO:")
print(codigo_minimo)